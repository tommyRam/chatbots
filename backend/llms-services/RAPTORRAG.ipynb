{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd742c2-c80d-4662-aa38-b7b8673572ca",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d757b1-715a-4280-a9f1-fad27aca802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from bs4 import BeautifulSoup as Soup \n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7ba755-5cc5-4ba9-841e-15beeea93ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "# LCEL docs\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# LCEL w/ PydanticOutputParser (outside the primary LCEL docs)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# LCEL w/ Self Query (outside the primary LCEL docs)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "# Doc texts\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "docs_texts = [d.page_content for d in docs]\n",
    "\n",
    "# Calculate the number of tokens for each document\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90e01c1-c762-47b6-b9b8-2bfcbf9a128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3270, 141, 141]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4d0d8f-1f90-4c27-b0c7-196cad9fcd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 3556\n"
     ]
    }
   ],
   "source": [
    "# Doc texts concat\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Num tokens in all context: %s\"\n",
    "    % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5038bf-7fb7-40d9-932a-b9a97eee1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc texts splits \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 100\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size_tok,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "texts_split = text_splitter.split_text(concatenated_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3eae0a3-f163-4949-b6cf-073f23f7c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e6f7a6-5d27-4570-8515-a233b52ff2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embd = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "model =  ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash-preview-05-20\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00af4ce-0578-44a7-81cf-c6c9da9a0418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy RAMAROKOTO\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 224\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Perform global dimensionality reduction on the embeddings using UMAP\n",
    "\n",
    "        Returns: A numpy array of the embeddings reduced to the specified dimensionality\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors = n_neighbors,\n",
    "        n_components=dim,\n",
    "        metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    num_neighbors: int = 10,\n",
    "    metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Perform local dimensionality reduction on the embeddings using UMAP, typically after global \n",
    "        clustering\n",
    "\n",
    "        Returns: A numpy array of the embeddings reduced to the specified dimensionality\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors,\n",
    "        n_components=dim,\n",
    "        metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray,\n",
    "    max_clusters: int = 50,\n",
    "    random_state: int = RANDOM_SEED\n",
    ") -> int: \n",
    "    \"\"\"\n",
    "        Determine the optimal number of clusters using the Bayesian Information Criterion (BIC)\n",
    "\n",
    "        Returns: An integer representing the optimal of clusters found\n",
    "    \"\"\"\n",
    "    max_clusters = min(max_clusters, len(embeddings))\n",
    "    n_clusters = np.arange(1, max_clusters)\n",
    "    bics = []\n",
    "    for n in n_clusters: \n",
    "        gm = GaussianMixture(n_components=n, random_state=random_state)\n",
    "        gm.fit(embeddings)\n",
    "        bics.append(gm.bic(embeddings))\n",
    "    return n_clusters[np.argmin(bics)]\n",
    "\n",
    "def GMM_cluster(\n",
    "    embeddings: np.ndarray,\n",
    "    threshold: float, \n",
    "    random_state: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "        Cluster embeddings using a Gaussian Mixture Model (GMM) based on probabiliy threshold\n",
    "\n",
    "        Returns: a tuple containing labels and the number of clusters determined\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings)\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters\n",
    "\n",
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int, \n",
    "    threshold: float\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "        Perform clustering on the embeddings by first reducing their dimensionality globally, then\n",
    "        clustering using a Gaussian Mixture Model, and finally performing local clustering within \n",
    "        each global clusters\n",
    "\n",
    "        Returns: A list of numpy arrays, where each array contains the cluster IDs for each embedding\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # Avoid clustering when there's insufficient data\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # Global dimensionality reduction\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # Global clustering \n",
    "    global_clusters, n_global_cluster = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # Iterate through each global cluster to perform local clustering\n",
    "    for i in range(n_global_cluster):\n",
    "        # Extract embeddings belonging to the current global cluster\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0: \n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # Handle small clusters with direct assignment\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else : \n",
    "            # Local dimensionality reduction and clustering \n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # Assign local cluster IDs, adjusting for total clusters already processed\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None].all(-1))[1]\n",
    "            )\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters\n",
    "\n",
    "def embed(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of text documents.\n",
    "\n",
    "    This function assumes the existence of an `embd` object with a method `embed_documents`\n",
    "    that takes a list of texts and returns their embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], a list of text documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An array of embeddings for the given text documents.\n",
    "    \"\"\"\n",
    "    text_embeddings = embd.embed_documents(texts)\n",
    "    text_embeddings_np = np.array(text_embeddings)\n",
    "    return text_embeddings_np\n",
    "\n",
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    Embeds a list of texts and clusters them, returning a DataFrame with texts, their embeddings, and cluster labels.\n",
    "\n",
    "    This function combines embedding generation and clustering into a single step. It assumes the existence\n",
    "    of a previously defined `perform_clustering` function that performs clustering on the embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], a list of text documents to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the original texts, their embeddings, and the assigned cluster labels.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # Generate embeddings\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # Perform clustering on the embeddings\n",
    "    df = pd.DataFrame()  # Initialize a DataFrame to store the results\n",
    "    df[\"text\"] = texts  # Store original texts\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # Store embeddings as a list in the DataFrame\n",
    "    df[\"cluster\"] = cluster_labels  # Store cluster labels\n",
    "    return df\n",
    "\n",
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Formats the text documents in a DataFrame into a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the 'text' column with text documents to format.\n",
    "\n",
    "    Returns:\n",
    "    - A single string where all text documents are joined by a specific delimiter.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()\n",
    "    return \"--- --- \\n --- --- \".join(unique_txt)\n",
    "\n",
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Embeds, clusters, and summarizes a list of texts. This function first generates embeddings for the texts,\n",
    "    clusters them based on similarity, expands the cluster assignments for easier processing, and then summarizes\n",
    "    the content within each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: A list of text documents to be processed.\n",
    "    - level: An integer parameter that could define the depth or detail of processing.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing two DataFrames:\n",
    "      1. The first DataFrame (`df_clusters`) includes the original texts, their embeddings, and cluster assignments.\n",
    "      2. The second DataFrame (`df_summary`) contains summaries for each cluster, the specified level of detail,\n",
    "         and the cluster identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed and cluster the texts, resulting in a DataFrame with 'text', 'embd', and 'cluster' columns\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # Prepare to expand the DataFrame for easier manipulation of clusters\n",
    "    expanded_list = []\n",
    "\n",
    "    # Expand DataFrame entries to document-cluster pairings for straightforward processing\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # Create a new DataFrame from the expanded list\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # Retrieve unique cluster identifiers for processing\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # Summarization\n",
    "    template = \"\"\"Here is a sub-set of LangChain Expression Language doc. \n",
    "    \n",
    "    LangChain Expression Language provides a way to compose chain in LangChain.\n",
    "    \n",
    "    Give a detailed summary of the documentation provided.\n",
    "    \n",
    "    Documentation:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Format text within each cluster for summarization\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # Create a DataFrame to store summaries with their corresponding cluster and level\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary\n",
    "\n",
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Recursively embeds, clusters, and summarizes texts up to a specified level or until\n",
    "    the number of unique clusters becomes 1, storing the results at each level.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], texts to be processed.\n",
    "    - level: int, current recursion level (starts at 1).\n",
    "    - n_levels: int, maximum depth of recursion.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], a dictionary where keys are the recursion\n",
    "      levels and values are tuples containing the clusters DataFrame and summaries DataFrame at that level.\n",
    "    \"\"\"\n",
    "    results = {}  # Dictionary to store results at each level\n",
    "\n",
    "    # Perform embedding, clustering, and summarization for the current level\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # Store the results of the current level\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # Determine if further recursion is possible and meaningful\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # Use summaries as the input texts for the next level of recursion\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # Merge the results from the next level into the current results dictionary\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27218eb-7b20-479e-979a-f72eda8d9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n"
     ]
    }
   ],
   "source": [
    "leaf_texts = docs_texts\n",
    "results = recursive_embed_cluster_summarize(leaf_texts, level=1, n_levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc897675-4787-4fd9-9176-bb3e06d1bb7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m     all_texts.extend(summaries)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Now, use all_texts to build the vectorstore with Chroma\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#vectorstore = Chroma.from_texts(texts=all_texts, embedding=embd)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m retriever = vectorstore.as_retriever()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    796\u001b[39m     **kwargs: Any,\n\u001b[32m    797\u001b[39m ) -> Chroma:\n\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[32m    799\u001b[39m \n\u001b[32m    800\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    815\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m     chroma_collection = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    827\u001b[39m         ids = [\u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:224\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize with a Chroma client.\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\chromadb\\__init__.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdminClient \u001b[38;5;28;01mas\u001b[39;00m AdminClientCreator\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncClient \u001b[38;5;28;01mas\u001b[39;00m AsyncClientCreator\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtoken_authn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TokenTransportHeader\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_DATABASE, DEFAULT_TENANT, Settings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\chromadb\\auth\\token_authn\\__init__.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m System\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaAuthError\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     OpenTelemetryGranularity,\n\u001b[32m     26\u001b[39m     trace_method,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m T = TypeVar(\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TracerProvider\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     BatchSpanProcessor,\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01motlp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace_exporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OTLPSpanExporter\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Component\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m System\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\trace_exporter\\__init__.py:22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Sequence\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelCredentials, Compression\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01motlp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     OTLPExporterMixin,\n\u001b[32m     24\u001b[39m     _get_credentials,\n\u001b[32m     25\u001b[39m     _translate_key_values,\n\u001b[32m     26\u001b[39m     environ_to_compression,\n\u001b[32m     27\u001b[39m     get_resource_data,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollector\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace_service_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     ExportTraceServiceRequest,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollector\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrace_service_pb2_grpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     TraceServiceStub,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:39\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merror_details_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetryInfo\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     ChannelCredentials,\n\u001b[32m     31\u001b[39m     Compression,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     ssl_channel_credentials,\n\u001b[32m     37\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     AnyValue,\n\u001b[32m     41\u001b[39m     ArrayValue,\n\u001b[32m     42\u001b[39m     KeyValue,\n\u001b[32m     43\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresource\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresource_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Resource\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopentelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     46\u001b[39m     OTEL_EXPORTER_OTLP_CERTIFICATE,\n\u001b[32m     47\u001b[39m     OTEL_EXPORTER_OTLP_COMPRESSION,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     OTEL_EXPORTER_OTLP_TIMEOUT,\n\u001b[32m     52\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\opentelemetry\\proto\\common\\v1\\common_pb2.py:36\u001b[39m\n\u001b[32m     11\u001b[39m _sym_db = _symbol_database.Default()\n\u001b[32m     16\u001b[39m DESCRIPTOR = _descriptor.FileDescriptor(\n\u001b[32m     17\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry/proto/common/v1/common.proto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m   package=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m   serialized_pb=\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m*opentelemetry/proto/common/v1/common.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x1d\u001b[39;00m\u001b[33mopentelemetry.proto.common.v1\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\x8c\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\x41\u001b[39;00m\u001b[33mnyValue\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x16\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[33mstring_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mbool_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x13\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mint_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x16\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\x64\u001b[39;00m\u001b[33mouble_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[33m@\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x61\u001b[39;00m\u001b[33mrray_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[33m).opentelemetry.proto.common.v1.ArrayValueH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x43\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[33mkvlist_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[33m+.opentelemetry.proto.common.v1.KeyValueListH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x15\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[33mytes_value\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x42\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[33mvalue\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mArrayValue\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x37\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33mvalues\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m.opentelemetry.proto.common.v1.AnyValue\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mG\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[33mKeyValueList\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x37\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33mvalues\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m.opentelemetry.proto.common.v1.KeyValue\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mO\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[33mKeyValue\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33mkey\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x36\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[33mvalue\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m.opentelemetry.proto.common.v1.AnyValue\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x16\u001b[39;00m\u001b[33mInstrumentationLibrary\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0f\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[33mversion\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[33mInstrumentationScope\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0f\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[33mversion\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mB[\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m io.opentelemetry.proto.common.v1B\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x43\u001b[39;00m\u001b[33mommonProtoP\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33mZ(go.opentelemetry.io/proto/otlp/common/v1b\u001b[39m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33mproto3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     28\u001b[39m _ANYVALUE = _descriptor.Descriptor(\n\u001b[32m     29\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mAnyValue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     30\u001b[39m   full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m   filename=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     32\u001b[39m   file=DESCRIPTOR,\n\u001b[32m     33\u001b[39m   containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m   create_key=_descriptor._internal_create_key,\n\u001b[32m     35\u001b[39m   fields=[\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43m_descriptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstring_value\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopentelemetry.proto.common.v1.AnyValue.string_value\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcreate_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_descriptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_internal_create_key\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     43\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     44\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mbool_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.bool_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m1\u001b[39m,\n\u001b[32m     45\u001b[39m       number=\u001b[32m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m8\u001b[39m, cpp_type=\u001b[32m7\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     46\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     47\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     48\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     49\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     50\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     51\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mint_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.int_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m2\u001b[39m,\n\u001b[32m     52\u001b[39m       number=\u001b[32m3\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m3\u001b[39m, cpp_type=\u001b[32m2\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     53\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[32m0\u001b[39m,\n\u001b[32m     54\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     55\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     56\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     57\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     58\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mdouble_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.double_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m3\u001b[39m,\n\u001b[32m     59\u001b[39m       number=\u001b[32m4\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m1\u001b[39m, cpp_type=\u001b[32m5\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     60\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[38;5;28mfloat\u001b[39m(\u001b[32m0\u001b[39m),\n\u001b[32m     61\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     63\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     64\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     65\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33marray_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.array_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m4\u001b[39m,\n\u001b[32m     66\u001b[39m       number=\u001b[32m5\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m11\u001b[39m, cpp_type=\u001b[32m10\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     67\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     68\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     69\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     70\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     71\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     72\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mkvlist_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.kvlist_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m5\u001b[39m,\n\u001b[32m     73\u001b[39m       number=\u001b[32m6\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m11\u001b[39m, cpp_type=\u001b[32m10\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     74\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     75\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     76\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     77\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     78\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     79\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mbytes_value\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.bytes_value\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m6\u001b[39m,\n\u001b[32m     80\u001b[39m       number=\u001b[32m7\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m12\u001b[39m, cpp_type=\u001b[32m9\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     81\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     83\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     84\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n\u001b[32m     85\u001b[39m   ],\n\u001b[32m     86\u001b[39m   extensions=[\n\u001b[32m     87\u001b[39m   ],\n\u001b[32m     88\u001b[39m   nested_types=[],\n\u001b[32m     89\u001b[39m   enum_types=[\n\u001b[32m     90\u001b[39m   ],\n\u001b[32m     91\u001b[39m   serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     92\u001b[39m   is_extendable=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     93\u001b[39m   syntax=\u001b[33m'\u001b[39m\u001b[33mproto3\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     94\u001b[39m   extension_ranges=[],\n\u001b[32m     95\u001b[39m   oneofs=[\n\u001b[32m     96\u001b[39m     _descriptor.OneofDescriptor(\n\u001b[32m     97\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.AnyValue.value\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     98\u001b[39m       index=\u001b[32m0\u001b[39m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     99\u001b[39m       create_key=_descriptor._internal_create_key,\n\u001b[32m    100\u001b[39m     fields=[]),\n\u001b[32m    101\u001b[39m   ],\n\u001b[32m    102\u001b[39m   serialized_start=\u001b[32m78\u001b[39m,\n\u001b[32m    103\u001b[39m   serialized_end=\u001b[32m346\u001b[39m,\n\u001b[32m    104\u001b[39m )\n\u001b[32m    107\u001b[39m _ARRAYVALUE = _descriptor.Descriptor(\n\u001b[32m    108\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mArrayValue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    109\u001b[39m   full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.ArrayValue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m   serialized_end=\u001b[32m417\u001b[39m,\n\u001b[32m    136\u001b[39m )\n\u001b[32m    139\u001b[39m _KEYVALUELIST = _descriptor.Descriptor(\n\u001b[32m    140\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mKeyValueList\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    141\u001b[39m   full_name=\u001b[33m'\u001b[39m\u001b[33mopentelemetry.proto.common.v1.KeyValueList\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m   serialized_end=\u001b[32m490\u001b[39m,\n\u001b[32m    168\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\google\\protobuf\\descriptor.py:621\u001b[39m, in \u001b[36mFieldDescriptor.__new__\u001b[39m\u001b[34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[32m    616\u001b[39m             default_value, message_type, enum_type, containing_type,\n\u001b[32m    617\u001b[39m             is_extension, extension_scope, options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    618\u001b[39m             serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    619\u001b[39m             has_default_value=\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof=\u001b[38;5;28;01mNone\u001b[39;00m, json_name=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    620\u001b[39m             file=\u001b[38;5;28;01mNone\u001b[39;00m, create_key=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m   \u001b[43m_message\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _message.default_pool.FindExtensionByName(full_name)\n",
      "\u001b[31mTypeError\u001b[39m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize all_texts with leaf_texts\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# Iterate through the results to extract summaries from each level and add them to all_texts\n",
    "for level in sorted(results.keys()):\n",
    "    # Extract summaries from the current level's DataFrame\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # Extend all_texts with the summaries from the current level\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# Now, use all_texts to build the vectorstore with Chroma\n",
    "#vectorstore = Chroma.from_texts(texts=all_texts, embedding=embd)\n",
    "vectorstore = Chroma.s(texts=all_texts, embedding=embd)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1819412b-772f-4378-9b8f-3c3ede4d95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy RAMAROKOTO\\Documents\\programmation\\projects\\New folder\\chatbots\\backend\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Chain\u001b[39;00m\n\u001b[32m     14\u001b[39m rag_chain = (\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mretriever\u001b[49m | format_docs, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: RunnablePassthrough()}\n\u001b[32m     16\u001b[39m     | prompt\n\u001b[32m     17\u001b[39m     | model\n\u001b[32m     18\u001b[39m     | StrOutputParser()\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Question\u001b[39;00m\n\u001b[32m     22\u001b[39m rag_chain.invoke(\u001b[33m\"\u001b[39m\u001b[33mHow to define a RAG chain? Give me a specific code example.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"How to define a RAG chain? Give me a specific code example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352dfa75-414e-4b68-83c8-d0713df36ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
