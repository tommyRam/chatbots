{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd85239-4bd5-42f5-bc16-7506e2f0dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fba3f36-42dc-4557-ac69-49364251e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3847f1-20b1-406e-8bcf-30c060c5fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf60f885-7224-4e4c-8392-8d540c17cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =  ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash-preview-05-20\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document: \\n\\n {doc}\")\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a983d6d9-471e-4553-bad3-3cfa5c433230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee180e1-fe84-4ed7-bb03-a45199f6b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(collection_name=\"summaries\", \n",
    "                    embedding_function=GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\"))\n",
    "\n",
    "# the storage layer for the parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add \n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e398303-f26f-4df0-a7ae-bfec29f6cc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This document by Lilian Weng explores the concept of LLM-powered autonomous agents, positioning Large Language Models (LLMs) as their core \"brain.\" These agents are enhanced by three key components:\\n\\n1.  **Planning:** Agents break down complex tasks into manageable subgoals using techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT). They also employ **self-reflection** to learn from past actions and refine future steps, utilizing frameworks such as ReAct (integrating reasoning and acting), Reflexion (dynamic memory and self-reflection to avoid inefficient trajectories), Chain of Hindsight (learning from feedback sequences), and Algorithm Distillation (applying self-improvement to reinforcement learning).\\n\\n2.  **Memory:** Analogous to human memory, agents use:\\n    *   **Short-term memory:** In-context learning within the LLM\\'s finite context window.\\n    *   **Long-term memory:** An external vector store for retaining and recalling vast amounts of information, accessed via fast retrieval methods like Maximum Inner Product Search (MIPS) using Approximate Nearest Neighbors (ANN) algorithms (e.g., LSH, ANNOY, HNSW, FAISS, ScaNN).\\n\\n3.  **Tool Use:** Agents extend their capabilities by calling external APIs and tools. Examples include MRKL (LLM as a router to expert modules), TALM and Toolformer (fine-tuning LLMs to use tools), ChatGPT Plugins, and HuggingGPT (using ChatGPT to plan and orchestrate models from HuggingFace). API-Bank is introduced as a benchmark for evaluating tool-augmented LLMs.\\n\\nThe document highlights several **case studies**:\\n*   **Scientific Discovery Agents** (e.g., ChemCrow) augment LLMs with domain-specific tools for tasks like drug discovery, showing superior performance over raw LLMs when evaluated by human experts.\\n*   **Generative Agents Simulation** demonstrates LLM-powered virtual characters interacting in a sandbox environment, exhibiting emergent social behaviors through memory streams, retrieval models, reflection mechanisms, and planning.\\n*   **Proof-of-Concept examples** like AutoGPT and GPT-Engineer showcase autonomous task execution and code generation, respectively, despite current reliability issues.\\n\\nFinally, the document identifies key **challenges** in building LLM-powered agents:\\n*   **Finite context length** limits the amount of historical information and detailed instructions.\\n*   **Difficulties in long-term planning and task decomposition**, as LLMs struggle to adapt to unexpected errors.\\n*   **Reliability of natural language interfaces**, which can lead to formatting errors and inconsistent behavior, requiring extensive parsing logic.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Memory in agents\"\n",
    "sub_docs = vectorstore.similarity_search(query, k=1)\n",
    "sub_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5292ea1-d949-46fd-a5ed-524fa8246ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three:\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query,n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20fe2e-0681-4c4f-9952-a4199657396b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
